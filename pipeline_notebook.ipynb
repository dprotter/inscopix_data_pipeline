{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import traceback\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline_functions:\n",
    "    def __init__(self, log_file = None):\n",
    "        '''nothing required'''\n",
    "        self.log_file = log_file\n",
    "    \n",
    "    \n",
    "    def print_processing(self, obj, step):\n",
    "        print(f'ID: {obj.sub_ID} efocus: {obj.efocus} is at step: {step}')\n",
    "                \n",
    "    def _dff(self, obj, f0type = 'mean', explicit_fname = None, overwrite = True):\n",
    "        '''run dff'''\n",
    "        step = 'dff'\n",
    "        obj.check_step(step)\n",
    "        file_out = self.get_output_filepath(obj,step) if not explicit_fname else explicit_fname\n",
    "        \n",
    "        if os.path.isfile(file_out):\n",
    "            if overwrite:\n",
    "                print(f'overwriting previous file at {file_out}')\n",
    "                os.remove(file_out)\n",
    "            else:\n",
    "                print(f'skipping processing and utilizing previous file at {file_out}')\n",
    "                return file_out\n",
    "\n",
    "        file_in = obj.previous_step_filepath\n",
    "        self.print_processing(obj, step)\n",
    "        isx.dff(file_in, file_out, f0_type=f0type)\n",
    "        return file_out\n",
    "    \n",
    "    def _preprocess(self, obj, temporal_downsample_factor=2,\n",
    "                        spatial_downsample_factor=1,\n",
    "                        crop_rect=None,\n",
    "                        fix_defective_pixels=True,\n",
    "                        trim_early_frames=True,\n",
    "                        explicit_fname = None,\n",
    "                        overwrite = True):\n",
    "        '''run preprocess'''\n",
    "        step = 'preprocess'\n",
    "        obj.check_step(step)\n",
    "        file_out = self.get_output_filepath(obj,step) if not explicit_fname else explicit_fname\n",
    "\n",
    "        if os.path.isfile(file_out):\n",
    "            if overwrite:\n",
    "                print(f'overwriting previous file at {file_out}')\n",
    "                os.remove(file_out)\n",
    "            else:\n",
    "                print(f'skipping processing and utilizing previous file at {file_out}')\n",
    "                return file_out\n",
    "\n",
    "        file_in = obj.previous_step_filepath\n",
    "        self.print_processing(obj, step)\n",
    "        isx.preprocess(file_in, file_out,\n",
    "                       temporal_downsample_factor=temporal_downsample_factor,\n",
    "                        spatial_downsample_factor=spatial_downsample_factor,\n",
    "                        crop_rect=crop_rect,\n",
    "                        fix_defective_pixels=fix_defective_pixels,\n",
    "                        trim_early_frames=trim_early_frames)\n",
    "        return file_out\n",
    "    \n",
    "    def _spatial_filter(self, obj, low_cutoff=0.005,\n",
    "                        high_cutoff=0.5,\n",
    "                        retain_mean=False,\n",
    "                        subtract_global_minimum=True,\n",
    "                        explicit_fname = None,\n",
    "                        overwrite = True):\n",
    "        \n",
    "        '''run spatial filter'''\n",
    "        step = 'spatial_filter'\n",
    "        obj.check_step(step)\n",
    "        file_out = self.get_output_filepath(obj,step) if not explicit_fname else explicit_fname\n",
    "\n",
    "        if os.path.isfile(file_out):\n",
    "            if overwrite:\n",
    "                print(f'overwriting previous file at {file_out}')\n",
    "                os.remove(file_out)\n",
    "            else:\n",
    "                print(f'skipping processing and utilizing previous file at {file_out}')\n",
    "                return file_out\n",
    "\n",
    "        file_in = obj.previous_step_filepath\n",
    "            \n",
    "        self.print_processing(obj, step)\n",
    "        \n",
    "        isx.spatial_filter(file_in, file_out,\n",
    "                                   low_cutoff=low_cutoff,\n",
    "                                    high_cutoff=high_cutoff,\n",
    "                                    retain_mean=retain_mean,\n",
    "                                    subtract_global_minimum=subtract_global_minimum,)\n",
    "        return file_out\n",
    "    \n",
    "    \n",
    "    def _check_step(self, obj, step):\n",
    "        if obj.previous_step_id > obj.parent_pipe.processing_order[step]:\n",
    "            print(f\"\"\"just fyi, youre running things out of the recommended order. your last \n",
    "                  step was {obj.order_lookup[obj.previous_step_id]}, and inscopix recommends\n",
    "                  preprocess -> spatial filter -> motion correct -> dff\"\"\")\n",
    "    \n",
    "    def get_trim_array(self, obj, indices, keep):\n",
    "        '''doc string here'''\n",
    "        \n",
    "        \n",
    "        if len(keep) == 0:\n",
    "            keep = [i for i in range(len(indices)+1)]\n",
    "            print(f'keep modified to {keep}')\n",
    "\n",
    "        #get the number of frames. i dont know if the API uses pythonic indexing\n",
    "        #or if it starts at 1. I will assume it starts at 1.\n",
    "        num_frames = isx.Movie.read(obj.previous_step_filepath).timing.num_samples\n",
    "\n",
    "        #assume for now we start and index 1 to get the first frame\n",
    "        start = [1]\n",
    "        stop = []\n",
    "        for index in indices:\n",
    "            stop += [index]\n",
    "            start += [index+1]\n",
    "\n",
    "        stop += [num_frames]\n",
    "        all_trims = []\n",
    "        fnames = []\n",
    "        \n",
    "        \n",
    "        for k in keep:\n",
    "            first= start[k]\n",
    "            last = stop[k]\n",
    "            \n",
    "            step = 'separate_movie'\n",
    "            #get the base filename\n",
    "            file_out = self.get_output_filepath(obj, step)   \n",
    "            \n",
    "            #modify the filename to include the indexes which it includes\n",
    "            file_out = self.append_name_general(file_out, f'{first}_to_{last}')\n",
    "            fnames += [file_out]\n",
    "\n",
    "            trim_array = []\n",
    "            if first == 1:\n",
    "                #remove everything after the stop frame\n",
    "                trim_array += [[last, num_frames]]\n",
    "\n",
    "            elif last == num_frames:\n",
    "                #remove everything from the first frame of the movie to the first frame\n",
    "                #of this 'crop.' PS I dont like inscopix's nomenclature\n",
    "                trim_array += [[1, first]]\n",
    "\n",
    "            else:\n",
    "                #remove before and after this set of indices\n",
    "                trim_array+=[[1,first]]\n",
    "                trim_array+=[[last,num_frames]]\n",
    "\n",
    "            all_trims += [trim_array]\n",
    "\n",
    "        return all_trims, fnames\n",
    "    \n",
    "    def _pca_ica(self, obj,\n",
    "                num_pcs=120,\n",
    "                num_ics=150,\n",
    "                unmix_type='spatial',\n",
    "                ica_temporal_weight=0.2,\n",
    "                max_iterations=100,\n",
    "                convergence_threshold=1e-05,\n",
    "                block_size=2000, explicit_fname = None,\n",
    "                overwrite = True):\n",
    "        \n",
    "        step = 'pca_ica'\n",
    "        obj.check_step(step)\n",
    "        \n",
    "        file_out = self.get_output_filepath(obj,step) if not explicit_fname else explicit_fname\n",
    "    \n",
    "        \n",
    "        \n",
    "        if os.path.isfile(file_out):\n",
    "            if overwrite:\n",
    "                print(f'overwriting previous file at {file_out}')\n",
    "                os.remove(file_out)\n",
    "            else:\n",
    "                print(f'skipping processing and utilizing previous file at {file_out}')\n",
    "                return file_out\n",
    "\n",
    "        file_in = obj.previous_step_filepath\n",
    "        \n",
    "        self.print_processing(obj, step)\n",
    "        \n",
    "        isx.pca_ica(input_movie_files=file_in,\n",
    "                    output_cell_set_files=file_out,\n",
    "                    num_pcs=num_pcs,\n",
    "                    num_ics=num_ics,\n",
    "                    unmix_type=unmix_type,\n",
    "                    ica_temporal_weight=ica_temporal_weight,\n",
    "                    max_iterations=max_iterations,\n",
    "                    convergence_threshold=convergence_threshold,\n",
    "                    block_size=block_size, \n",
    "                     )\n",
    "        return file_out\n",
    "        \n",
    "    \n",
    "    def _de_interleave(self, obj, overwrite = True):\n",
    "        step = 'de_interleave'\n",
    "        planes = obj.get_focal_planes()\n",
    "        \n",
    "        file_out = self.get_output_filepath(obj,'')\n",
    "\n",
    "        fnames_out = [self.append_name_general(file_out, f'efocus_{focus}') for focus in planes]\n",
    "        try:\n",
    "            fname_check = [os.path.isfile(file_out) for file in fnames_out]\n",
    "            \n",
    "            #do any output files already exist?\n",
    "            if any(fname_check):\n",
    "                \n",
    "                #remove files that exist \n",
    "                if overwrite:\n",
    "                    for file_out in fnames_out:\n",
    "                        if os.path.isfile(file_out):\n",
    "                            print(f'overwriting previous file at {file_out}')\n",
    "                            os.remove(file_out)\n",
    "                \n",
    "                #if not overwriting AND all files already exist, return as if processing is complete     \n",
    "                elif all(fname_check):\n",
    "                    return fnames_out, planes\n",
    "                \n",
    "                #if not overwriting and SOME files already exist, remove just those files from the list of files to be processed\n",
    "                else:\n",
    "                    for fname in fnames_out:\n",
    "                        if os.path.isfile(file_out):\n",
    "                            fnames_out.remove(fname)\n",
    "            \n",
    "            \n",
    "            isx.de_interleave(obj.previous_step_filepath, fnames_out, planes)\n",
    "            return fnames_out, planes\n",
    "        \n",
    "        except:\n",
    "            print(f'there was a problem running {step}.')\n",
    "            traceback.print_exc()\n",
    "            obj.failed = True\n",
    "        return fnames_out, planes\n",
    "    \n",
    "    def append_name_general(self, input_name, append_str):\n",
    "        vals = input_name.split('.')\n",
    "        return vals[0] + '_' + append_str + '.' + vals[1]\n",
    "    \n",
    "    def get_output_filepath(self, obj, step):\n",
    "        '''take in the current step and return a suitable filename'''\n",
    "        if step not in obj.file_mods.keys():\n",
    "            print(f'\"{step}\" not in file_modification lookup, dictionary. Will add the string that was passed.')\n",
    "            append_string = step\n",
    "        else:\n",
    "            append_string = obj.file_mods[step]\n",
    "        file_in = obj.previous_step_filepath\n",
    "        path, fname = os.path.split(file_in)\n",
    "        if obj.output_dir != path:\n",
    "            file_out = os.path.join(obj.output_dir, fname)\n",
    "            file_out = self.append_name_general(file_out,append_string)\n",
    "        else:\n",
    "            file_out = self.append_name_general(file_in, append_string)\n",
    "        return file_out\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _separate_movie(self, obj, \n",
    "                        indices, \n",
    "                        keep = [], \n",
    "                        explicit_fname = None, \n",
    "                        overwrite = True):\n",
    "        '''separate a movie'''\n",
    "        raise Exception('separate movie not properly implemented')\n",
    "        step = 'separate_movie'\n",
    "        obj.check_step(step)\n",
    "        trim_arrays, fname_array = self.get_trim_array(obj,indices, keep)\n",
    "        \n",
    "\n",
    "            \n",
    "        self.print_processing(obj, step)\n",
    "        \n",
    "        #lets just make super clear this var is only for a select case\n",
    "        if explicit_fname:\n",
    "            file_iterator = 0\n",
    "            new_fname_array = []\n",
    "            \n",
    "        for trim_arr, file_out in zip(trim_arrays, fname_array):\n",
    "            \n",
    "            if explicit_fname:\n",
    "                file_out = self.append_name_general(explicit_fname, str(file_iterator))\n",
    "                file_iterator += 1\n",
    "                new_fname_array += [file_out]\n",
    "            \n",
    "            '''this is not ready yet, '''\n",
    "            if overwrite:\n",
    "                if os.path.isfile(file_out):\n",
    "                    print(f'overwriting previous file at {file_out}')\n",
    "                    os.remove(file_out)\n",
    "                else:\n",
    "                    return file_out\n",
    "                try: \n",
    "                    file_in = obj.previous_step_filepath\n",
    "                    isx.trim_movie(file_in, file_out,trim_arr )\n",
    "                except:\n",
    "                    print(f'there was a problem running {step}.')\n",
    "                    traceback.print_exc()\n",
    "                    obj.failed = True\n",
    "            \n",
    "            #replace the original filename array with the one created from the \n",
    "            #explicit filename\n",
    "            if explicit_fname:\n",
    "                fname_array = new_fname_array\n",
    "            \n",
    "        return fname_array\n",
    "    \n",
    "    def _run_cnmfe(self, obj, processing_directory, \n",
    "                   cell_diameter = 20,\n",
    "                min_corr = 0.8,\n",
    "                min_pnr = 10,\n",
    "                bg_spatial_subsampling = 2,\n",
    "                ring_size_factor = 1.4,\n",
    "                gaussian_kernel_size = 0,\n",
    "                closing_kernel_size = 0,\n",
    "                merge_threshold = 0.7,\n",
    "                processing_mode = 'parallel_patches',\n",
    "                num_threads = 4,\n",
    "                patch_size = 80,\n",
    "                patch_overlap = 20,\n",
    "                output_unit_type = 'df_over_noise',\n",
    "                explicit_fname = None, \n",
    "                overwrite = True): \n",
    "                \n",
    "        step = 'cnmfe'\n",
    "        obj.check_step(step)\n",
    "        \n",
    "        file_out = self.get_output_filepath(obj,step) if not explicit_fname else explicit_fname\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        if os.path.isfile(file_out):\n",
    "            if overwrite:\n",
    "                print(f'overwriting previous file at {file_out}')\n",
    "                os.remove(file_out)\n",
    "            else:\n",
    "                print(f'skipping processing and utilizing previous file at {file_out}')\n",
    "                return file_out\n",
    "\n",
    "        file_in = obj.previous_step_filepath\n",
    "        \n",
    "        self.print_processing(obj, step)\n",
    "        \n",
    "        isx.run_cnmfe(input_movie_files=file_in,\n",
    "                    output_cell_set_files=file_out,\n",
    "                    output_dir=processing_directory,\n",
    "                    cell_diameter = cell_diameter,\n",
    "                        min_corr = min_corr,\n",
    "                        min_pnr = min_pnr,\n",
    "                        bg_spatial_subsampling = bg_spatial_subsampling,\n",
    "                        ring_size_factor = ring_size_factor,\n",
    "                        gaussian_kernel_size = gaussian_kernel_size,\n",
    "                        closing_kernel_size = closing_kernel_size,\n",
    "                        merge_threshold =  merge_threshold,\n",
    "                        processing_mode = processing_mode,\n",
    "                        num_threads = num_threads,\n",
    "                        patch_size = patch_size,\n",
    "                        patch_overlap = patch_overlap,\n",
    "                        output_unit_type = output_unit_type,)\n",
    "        return file_out\n",
    "        \n",
    "    def _motion_correct(self, obj,\n",
    "                        max_translation=20,\n",
    "                        low_bandpass_cutoff=0.004,\n",
    "                        high_bandpass_cutoff=0.016,\n",
    "                        roi=None,\n",
    "                        reference_segment_index=0,\n",
    "                        reference_frame_index=0,\n",
    "                        reference_file_name='',\n",
    "                        global_registration_weight=1.0,\n",
    "                        output_translation_files=None,\n",
    "                        output_crop_rect_file=None,\n",
    "                        explicit_fname = None,\n",
    "                        overwrite = True):\n",
    "        \n",
    "        step = 'motion_correct'\n",
    "        obj.check_step(step)\n",
    "        \n",
    "        file_out = self.get_output_filepath(obj,step) if not explicit_fname else explicit_fname\n",
    "        \n",
    "        #need to make some output files for translation csv and output translation file csv\n",
    "        head, tail = os.path.split(file_out)\n",
    "        fname = tail.split('.')[0]\n",
    "        output_translation_file =  os.path.join(head, (fname+'translations'+'.csv'))\n",
    "        output_crop_rect_file =  os.path.join(head, (fname+'mc_crop'+'.csv'))\n",
    "        \n",
    "        if os.path.isfile(file_out):\n",
    "            if overwrite:\n",
    "                print(f'overwriting previous file at {file_out}')\n",
    "                os.remove(file_out)\n",
    "            else:\n",
    "                print(f'skipping processing and utilizing previous file at {file_out}')\n",
    "                return file_out\n",
    "\n",
    "        file_in = obj.previous_step_filepath\n",
    "        \n",
    "        self.print_processing(obj, step)\n",
    "        \n",
    "        isx.motion_correct(file_in,\n",
    "                            file_out,\n",
    "                            max_translation=max_translation,\n",
    "                            low_bandpass_cutoff=low_bandpass_cutoff,\n",
    "                            high_bandpass_cutoff=high_bandpass_cutoff,\n",
    "                            roi=roi,\n",
    "                            reference_segment_index=reference_segment_index,\n",
    "                            reference_frame_index=reference_frame_index,\n",
    "                            reference_file_name=reference_file_name,\n",
    "                            global_registration_weight=global_registration_weight,\n",
    "                            output_translation_files=output_translation_file,\n",
    "                            output_crop_rect_file=output_crop_rect_file,\n",
    "                            )\n",
    "        return file_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video_Pipe:\n",
    "    pf = pipeline_functions()\n",
    "    def __init__(self, input_path, session_info_file, \n",
    "                 output_dir = None, overwrite = True):\n",
    "        \n",
    "        #if True, reprocess and overwrite found files\n",
    "        self.overwrite = overwrite\n",
    "        \n",
    "        with open(session_info_file) as f:\n",
    "            session_info_json = json.load(f)\n",
    "        self.session_info = session_info_json\n",
    "        self.name = self.session_info['name']\n",
    "        self.efocus = None\n",
    "        self.saved_location = None\n",
    "        self.previous_step_id = 0\n",
    "        self.source_video_path = input_path\n",
    "        \n",
    "        input_dir, fname = os.path.split(input_path) \n",
    "        self.original_video_name = fname\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir if output_dir else input_dir\n",
    "        \n",
    "        self.default_order = {'preprocess':1, 'de_interleave':0.5, 'spatial_filter':2, \n",
    "                              'separate_movie':2.5,\n",
    "                              'motion_correct':3,\n",
    "                              'dff':4, 'pca_ica':5, 'cnmfe':5.5, 'categorize_cells':6,\n",
    "                              'longitudinal_registration':6.5, \n",
    "                             'multiplane_registration':7.5}\n",
    "        self.file_mods = {'preprocess':'pp', 'spatial_filter':'sf', 'motion_correct':'mc',\n",
    "                              'dff':'dff', 'separate_movie':'frames', 'pca_ica':'pca_ica', 'cnmfe':'cnmfe'}\n",
    "        \n",
    "        #if we want to automate the order of processing, and useful for warning the user\n",
    "        #if processing is happening outside of the expected order\n",
    "        self.processing_order = self.default_order\n",
    "        #reverse lookup of order (ie 1:'preprocess')\n",
    "        self.order_lookup = {self.default_order[key]:key for key in sorted(self.default_order.keys())}\n",
    "\n",
    "        \n",
    "        first_sub = SubPipe(self, 1)\n",
    "        first_sub.previous_step_filepath = self.source_video_path\n",
    "        self.subordinates = {1:first_sub}\n",
    "        self.cleanup_files = []\n",
    "        \n",
    "\n",
    "    def check_status(self):\n",
    "        sub0 = self.subordinates[1]\n",
    "        subs = self.get_bottom_subs(sub0)\n",
    "        for sub in subs:\n",
    "            print('*****************************')\n",
    "            print(f'SubPipe {sub.sub_ID} is at step {self.order_lookup[sub.previous_step_id]}')\n",
    "            print(f'the most recent file is\\n{sub.previous_step_filepath}')\n",
    "            print(f'files to be removed:\\n{self.cleanup_files}')\n",
    "            print('*****************************\\n')\n",
    "            \n",
    "    def get_bottom_subs(self, sub, flatten = True):\n",
    "        next_processing_subs = []\n",
    "        if sub.children:\n",
    "            for child in sub.children:\n",
    "                if child.children:\n",
    "                    next_processing_subs += [self.get_bottom_subs(child)]\n",
    "                else:\n",
    "                    next_processing_subs +=[child]\n",
    "        else:\n",
    "            next_processing_subs +=[sub]\n",
    "        if flatten:\n",
    "            return [val for val in self.flatten_sublist(next_processing_subs)]\n",
    "        else:\n",
    "            return next_processing_subs\n",
    "        \n",
    "    def preprocess(self, sub_list = None, \n",
    "                   temporal_downsample_factor=2,\n",
    "                    spatial_downsample_factor=1,\n",
    "                    crop_rect=None,\n",
    "                    fix_defective_pixels=True,\n",
    "                    trim_early_frames=True,\n",
    "                    explicit_fname = None, \n",
    "                    remove_file_on_cleanup = True,\n",
    "                    overwrite = True):\n",
    "        \n",
    "        step = 'preprocess'\n",
    "        if not sub_list:\n",
    "            sub_list = self.get_bottom_subs(self.subordinates[1])\n",
    "            \n",
    "        for sub in sub_list:  \n",
    "            \n",
    "            try:\n",
    "                \n",
    "                fpath = self.pf._preprocess(sub,\n",
    "                               temporal_downsample_factor=temporal_downsample_factor,\n",
    "                                spatial_downsample_factor=spatial_downsample_factor,\n",
    "                                crop_rect=crop_rect,\n",
    "                                fix_defective_pixels=fix_defective_pixels,\n",
    "                                trim_early_frames=trim_early_frames,\n",
    "                                explicit_fname = explicit_fname,\n",
    "                                overwrite=overwrite)\n",
    "                \n",
    "            except:\n",
    "                print(f'there was a problem running {step} on SubPipe ID: {sub.sub_ID}.')\n",
    "                traceback.print_exc()\n",
    "                sub.failed = True\n",
    "            else:\n",
    "                sub.update_processing_step(step = 'preprocess', file_path = fpath)\n",
    "            \n",
    "                if remove_file_on_cleanup:\n",
    "                    self.cleanup_files.append(fpath)\n",
    "            \n",
    "            self.check_failed(step)\n",
    "            \n",
    "            \n",
    "\n",
    "    def check_failed(self, step):\n",
    "        failed_list = []\n",
    "        failed_dict = {}\n",
    "        for k in self.subordinates.keys():\n",
    "            sub = self.subordinates[k]\n",
    "            failed_list += [sub.failed]\n",
    "            failed_dict[k] = sub.failed\n",
    "        \n",
    "        if all(failed_list):\n",
    "            print(f'all subordinates have failed at {step}')\n",
    "            return True, failed_dict\n",
    "        elif any(failed_list):\n",
    "            print(f'some subordinates have failed {step}:')\n",
    "            print(failed_dict)\n",
    "            return False, failed_dict\n",
    "        else:\n",
    "            return False, failed_dict\n",
    "        \n",
    "    \n",
    "    def spatial_filter(self, sub_list = None, \n",
    "                       low_cutoff=0.005,\n",
    "                        high_cutoff=0.5,\n",
    "                        retain_mean=False,\n",
    "                        subtract_global_minimum=True,\n",
    "                       explicit_fname = None, \n",
    "                       remove_file_on_cleanup = True,\n",
    "                       overwrite = True):\n",
    "        \n",
    "        step = 'spatial_filter'\n",
    "\n",
    "        if not sub_list:\n",
    "            sub_list = self.get_bottom_subs(self.subordinates[1])\n",
    "            \n",
    "        for sub in sub_list:\n",
    "\n",
    "            if not sub.failed:\n",
    "                try:\n",
    "                    fpath = self.pf._spatial_filter(sub, \n",
    "                                low_cutoff=low_cutoff,\n",
    "                                high_cutoff=high_cutoff,\n",
    "                                retain_mean=retain_mean,\n",
    "                                subtract_global_minimum=subtract_global_minimum,\n",
    "                                explicit_fname = explicit_fname,\n",
    "                                overwrite=overwrite)\n",
    "                    \n",
    "                except:\n",
    "                    print(f'SubPipe {sub.sub_ID} has failed at {step}')\n",
    "                    sub.failed = True\n",
    "                else:\n",
    "                    sub.update_processing_step(step, fpath)\n",
    "                    if remove_file_on_cleanup:\n",
    "                        self.cleanup_files.append(fpath)\n",
    "            \n",
    "        self.check_failed(step)\n",
    "        \n",
    "        \n",
    "    def append_name_general(self,input_name, append_str):\n",
    "        vals = input_name.split('.')\n",
    "        return vals[0] + '_' + append_str + '.' + vals[1]\n",
    "    \n",
    "    def append_vid_name(self,append_str):\n",
    "        vals = self.video_name('.')\n",
    "        return vals[0] + '_' + append_str + '.' + vals[1]\n",
    "    \n",
    "\n",
    "    def new_sub(self):\n",
    "        ID = max(self.subordinates.keys()) + 1\n",
    "        s = SubPipe(self, ID)\n",
    "        self.subordinates[ID] = s\n",
    "        return s\n",
    "\n",
    "    \n",
    "    def all_subs_failed(self):\n",
    "        '''check if all subordinates have failed'''\n",
    "        failed = [self.subordinates_failed[k] for k in self.subordinates_failed.keys()]\n",
    "        return all(failed)['microscope']['multiplane']\n",
    "\n",
    "        out = []\n",
    "        multi = self.session_info['microscope']['multiplane']['planes']\n",
    "        for key in sorted(multi.keys()):\n",
    "            if multi[key]['enabled']:\n",
    "                out+=[ int(multi[key]['focus'])]\n",
    "        return out\n",
    "    \n",
    "    def save(self, file, update_save_location = True):\n",
    "        \n",
    "        #create a temp file so that if there is an issue saving we dont\n",
    "        #overwrite our saved object\n",
    "        path, _ = os.path.split(file)\n",
    "        temp = os.path.join(path,'temp_pickle')\n",
    "        try:\n",
    "            \n",
    "            with open(temp, 'wb') as f:\n",
    "                self.saved_location = file\n",
    "                pickle.dump(self, f)\n",
    "        except:\n",
    "            \n",
    "            print('couldnt save this VideoPipe!')\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            #remove the empty file\n",
    "            os.remove(temp)\n",
    "        else:\n",
    "            #cleanup by rename the temp file to the users fname\n",
    "            os.rename(temp, file)\n",
    "            \n",
    "            if update_save_location:\n",
    "                self.saved_location = file\n",
    "    \n",
    "    def load(self, file):\n",
    "        \"\"\"i wonder if this will expload?\"\"\"\n",
    "        with open(file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        \n",
    "    def reload(self):\n",
    "        \"\"\"i wonder if this will expload?\"\"\"\n",
    "        if not self.saved_location:\n",
    "            raise Exception('There is no saved file associated with this VideoPipe instance')\n",
    "        with open(self.saved_location, 'rb') as f:\n",
    "            self = pickle.load(f)\n",
    "    \n",
    "    def get_focal_planes(self):\n",
    "\n",
    "        out = []\n",
    "        multi = self.session_info['microscope']['multiplane']['planes']\n",
    "        for key in sorted(multi.keys()):\n",
    "            out+=[ int(multi[key]['focus'])]\n",
    "        return out\n",
    "           \n",
    "    def de_interleave(self, sub_list = None, \n",
    "                      remove_file_on_cleanup = True,\n",
    "                      overwrite = True):\n",
    "        step = 'de_interleave'\n",
    "        \n",
    "        if not sub_list:\n",
    "            sub_list = self.get_bottom_subs(self.subordinates[1])\n",
    "        \n",
    "        for sub in sub_list:\n",
    "            try:\n",
    "                fnames, planes = self.pf._de_interleave(sub,overwrite=overwrite)\n",
    "                print(fnames)\n",
    "                print(planes)\n",
    "                \n",
    "            except:\n",
    "                print(f'there was a problem running {step} on SubPipe ID: {sub.sub_ID}.\\n{traceback.print_exc()}')\n",
    "                \n",
    "                self.failed = True\n",
    "            else:\n",
    "                for fname, plane in zip(fnames, planes):\n",
    "                    \n",
    "                    new_sub = self.new_sub()\n",
    "                    new_sub.parent_sub = sub\n",
    "                    new_sub.efocus = plane\n",
    "                    new_sub.sub_type = 'single_plane'\n",
    "                    new_sub.update_processing_step('de_interleave', fname)\n",
    "                    sub.children+= [new_sub]\n",
    "                    \n",
    "                    if remove_file_on_cleanup:\n",
    "                        self.cleanup_files.append(fname)\n",
    "                    \n",
    "                \n",
    "    def motion_correct(self, sub_list = None, \n",
    "                       max_translation=20,\n",
    "                        low_bandpass_cutoff=0.004,\n",
    "                        high_bandpass_cutoff=0.016,\n",
    "                        roi=None,\n",
    "                        reference_segment_index=0,\n",
    "                        reference_frame_index=20,\n",
    "                        reference_file_name='',\n",
    "                        global_registration_weight=1.0,\n",
    "                        output_translation_files=None,\n",
    "                        output_crop_rect_file=None,\n",
    "                        explicit_fname = None,\n",
    "                        overwrite = True):\n",
    "        \n",
    "        step = 'motion_correct'\n",
    "\n",
    "        if not sub_list:\n",
    "            sub_list = self.get_bottom_subs(self.subordinates[1])\n",
    "            \n",
    "        for sub in sub_list:\n",
    "\n",
    "            if not sub.failed:\n",
    "                try:\n",
    "                    fpath = self.pf._motion_correct(sub, \n",
    "                                max_translation=max_translation,\n",
    "                                low_bandpass_cutoff=low_bandpass_cutoff,\n",
    "                                high_bandpass_cutoff=high_bandpass_cutoff,\n",
    "                                roi=roi,\n",
    "                                reference_segment_index=reference_segment_index,\n",
    "                                reference_frame_index=reference_frame_index,\n",
    "                                reference_file_name=reference_file_name,\n",
    "                                global_registration_weight=global_registration_weight,\n",
    "                                output_translation_files=output_translation_files,\n",
    "                                output_crop_rect_file=output_crop_rect_file,\n",
    "                                explicit_fname = explicit_fname,\n",
    "                                overwrite=overwrite)\n",
    "                \n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    print(f'SubPipe {sub.sub_ID} has failed at {step}')\n",
    "                    sub.failed = True\n",
    "                else:\n",
    "                    sub.update_processing_step(step, fpath)\n",
    "            \n",
    "        self.check_failed(step)\n",
    "        \n",
    "        \n",
    "    def dff(self, sub_list = None, f0type = 'mean', explicit_fname = None, overwrite = True):\n",
    "        '''available dff types = mean, min'''\n",
    "        step = 'dff'\n",
    "\n",
    "        if not sub_list:\n",
    "            sub_list = self.get_bottom_subs(self.subordinates[1])\n",
    "\n",
    "        for sub in sub_list:\n",
    "\n",
    "            if not sub.failed:\n",
    "                try:\n",
    "                    fpath = self.pf._dff(sub, f0type = f0type, \n",
    "                                         explicit_fname = explicit_fname)\n",
    "\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    print(f'SubPipe {sub.sub_ID} has failed at {step}')\n",
    "                    sub.failed = True\n",
    "                else:\n",
    "                    sub.update_processing_step(step, fpath)\n",
    "\n",
    "        self.check_failed(step)\n",
    "    \n",
    "    def pca_ica(self, sub_list = None,\n",
    "                num_pcs=120,\n",
    "                num_ics=150,\n",
    "                unmix_type='spatial',\n",
    "                ica_temporal_weight=0.2,\n",
    "                max_iterations=100,\n",
    "                convergence_threshold=1e-05,\n",
    "                block_size=2000, explicit_fname = None,\n",
    "                overwrite = True):\n",
    "        '''HEY! \n",
    "        you need to optimize this a bit for NAc, specifically taking a look at the \n",
    "        ica temporal weight'''\n",
    "        \n",
    "        step = 'pca_ica'\n",
    "        \n",
    "        if not sub_list:\n",
    "            sub_list = self.get_bottom_subs(self.subordinates[1])\n",
    "\n",
    "        for sub in sub_list:\n",
    "\n",
    "            if not sub.failed:\n",
    "                try:\n",
    "                    fpath = self.pf._pca_ica(sub,\n",
    "                                            num_pcs=num_pcs,\n",
    "                                            num_ics=num_ics,\n",
    "                                            unmix_type=unmix_type,\n",
    "                                            ica_temporal_weight=ica_temporal_weight,\n",
    "                                            max_iterations=max_iterations,\n",
    "                                            convergence_threshold=convergence_threshold,\n",
    "                                            block_size=block_size, \n",
    "                                             explicit_fname = None,\n",
    "                                             overwrite=overwrite)\n",
    "\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    print(f'SubPipe {sub.sub_ID} has failed at {step}')\n",
    "                    sub.failed = True\n",
    "                else:\n",
    "                    sub.update_processing_step(step, fpath)\n",
    "\n",
    "        self.check_failed(step)\n",
    "\n",
    "    def run_cnmfe(self, sub_list = None,\n",
    "                cell_diameter = 13,\n",
    "                min_corr = 0.8,\n",
    "                min_pnr = 10,\n",
    "                bg_spatial_subsampling = 2,\n",
    "                ring_size_factor = 1.4,\n",
    "                gaussian_kernel_size = 0,\n",
    "                closing_kernel_size = 0,\n",
    "                merge_threshold = 0.7,\n",
    "                processing_mode = 'parallel_patches',\n",
    "                num_threads = 4,\n",
    "                patch_size = 80,\n",
    "                patch_overlap = 20,\n",
    "                output_unit_type = 'df_over_noise',\n",
    "                explicit_fname = None,\n",
    "                overwrite = True):\n",
    "        \n",
    "        \n",
    "        step = 'cnmfe'\n",
    "        \n",
    "        if not sub_list:\n",
    "            sub_list = self.get_bottom_subs(self.subordinates[1])\n",
    "\n",
    "        for sub in sub_list:\n",
    "\n",
    "            if not sub.failed:\n",
    "                try:\n",
    "                    new_dir_name = f'{sub.sub_ID}_{sub.efocus}'\n",
    "                    file_in = sub.previous_step_filepath\n",
    "                    path, fname = os.path.split(file_in)\n",
    "                    processing_directory = os.path.join(path, new_dir_name)\n",
    "                    if not os.path.isdir(processing_directory):\n",
    "                        os.mkdir(processing_directory)\n",
    "                    fpath = self.pf._run_cnmfe(sub,\n",
    "                                               processing_directory=processing_directory,\n",
    "                                            cell_diameter = cell_diameter,\n",
    "                                            min_corr = min_corr,\n",
    "                                            min_pnr = min_pnr,\n",
    "                                            bg_spatial_subsampling = bg_spatial_subsampling,\n",
    "                                            ring_size_factor = ring_size_factor,\n",
    "                                            gaussian_kernel_size = gaussian_kernel_size,\n",
    "                                            closing_kernel_size = closing_kernel_size,\n",
    "                                            merge_threshold =  merge_threshold,\n",
    "                                            processing_mode = processing_mode,\n",
    "                                            num_threads = num_threads,\n",
    "                                            patch_size = patch_size,\n",
    "                                            patch_overlap = patch_overlap,\n",
    "                                            output_unit_type = output_unit_type,\n",
    "                                            explicit_fname = explicit_fname,\n",
    "                                            overwrite=overwrite)\n",
    "\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    print(f'SubPipe {sub.sub_ID} has failed at {step}')\n",
    "                    sub.failed = True\n",
    "                else:\n",
    "                    sub.update_processing_step(step, fpath)\n",
    "\n",
    "        self.check_failed(step)\n",
    "\n",
    "    def flatten_sublist(self, slist):\n",
    "        '''create a generator to quickly flatten lists of lists of... n lists.\n",
    "        used to flatten the output of \"get_bottom_subs\" into a convenient interable\n",
    "        \n",
    "        for example: \n",
    "        lol = [[1,2,3], [ [4,5],[6,7] ], 8]\n",
    "        output = [i for i in vp.flatten_sublist(lol)]\n",
    "        print(output)\n",
    "        >>>[1,2,3,4,5,6,7,8]\n",
    "        '''\n",
    "        for element in slist:\n",
    "            if isinstance(element, list):\n",
    "                yield from self.flatten_sublist(element)\n",
    "            else:\n",
    "                yield element\n",
    "    \n",
    "    def clean_up(self):\n",
    "        _, failed_dict = self.check_failed()\n",
    "        any_failed = any([v for k,v in failed_dict.items()])\n",
    "        for file in self.cleanup_files:\n",
    "            if os.path.isfile(file):\n",
    "                try:\n",
    "                    os.remove(file)\n",
    "                except:\n",
    "                    print('error removing file:\\n{file}')\n",
    "                else:\n",
    "                    self.cleanup_files.remove(file)\n",
    "                \n",
    "            else:\n",
    "                print(f'tried to cleanup file, but it did not exist:\\n{file}')\n",
    "\n",
    "    def cleanup_cnmfe_mem_maps(self,):\n",
    "        '''in progress shutil.rmtree(\"path_to_dir\")'''\n",
    "                \n",
    "                \n",
    "class SubPipe:\n",
    "    pf = pipeline_functions()\n",
    "    def __init__(self, parent_pipeline, ID, parent_sub = None):\n",
    "        self.efocus = None\n",
    "        self.parent_pipe = parent_pipeline\n",
    "        self.subtype = ''\n",
    "        self.sub_ID = ID\n",
    "        self.video_name = parent_pipeline.original_video_name\n",
    "        self.default_order = parent_pipeline.default_order\n",
    "        self.file_mods = parent_pipeline.file_mods\n",
    "        self.order_lookup = parent_pipeline.order_lookup\n",
    "        self.input_dir = parent_pipeline.input_dir\n",
    "        self.session_info = parent_pipeline.session_info\n",
    "        self.output_dir = parent_pipeline.output_dir\n",
    "        self.previous_step_filepath = None\n",
    "        self.previous_step_id = parent_sub.previous_step_id if parent_sub else parent_pipeline.previous_step_id\n",
    "        \n",
    "        self.failed = False\n",
    "        \n",
    "        self.children = []\n",
    "    \n",
    "    def update_processing_step(self, step, file_path):\n",
    "        self.previous_step_filepath = file_path\n",
    "        self.previous_step_id = self.parent_pipe.default_order[step]\n",
    "        \n",
    "    def get_focal_planes(self):\n",
    "        return self.parent_pipe.get_focal_planes()\n",
    "    \n",
    "    def check_step(self,step):\n",
    "        self.pf._check_step(self, step)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test_file = '/home/dprotter/Documents/Scratch Data Analysis/pipe_test_data/Session-20201102-141754_3558_operant/2020-11-02-14-40-34_video.isxd'\\nsession_file = '/home/dprotter/Documents/Scratch Data Analysis/pipe_test_data/Session-20201102-141754_3558_operant/session.json'   \\noutput_dir = '/home/dprotter/Documents/Scratch Data Analysis/pipe_test_data/python_output'\\nvp = Video_Pipe(test_file, session_info_file = session_file, output_dir = output_dir)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test_file = '/home/dprotter/Documents/Scratch Data Analysis/pipe_test_data/Session-20201102-141754_3558_operant/2020-11-02-14-40-34_video.isxd'\n",
    "session_file = '/home/dprotter/Documents/Scratch Data Analysis/pipe_test_data/Session-20201102-141754_3558_operant/session.json'   \n",
    "output_dir = '/home/dprotter/Documents/Scratch Data Analysis/pipe_test_data/python_output'\n",
    "vp = Video_Pipe(test_file, session_info_file = session_file, output_dir = output_dir)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import time\n",
    "start = time.time()\n",
    "file = '/mnt/working_storage/spring 2022/Session-20220204-140455_4345_imagePPT/2022-02-04-14-48-32_video.isxd'\n",
    "output = '/mnt/working_storage/spring 2022/4345_project/4345/python_output'\n",
    "session_file = '/mnt/working_storage/spring 2022/Session-20220204-140455_4345_imagePPT/session.json'\n",
    "\n",
    "vp = Video_Pipe(file, session_info_file = session_file, output_dir = output)\n",
    "\n",
    "vp.de_interleave()\n",
    "print(f'preprocessed in {time.time() - start} seconds')\n",
    "vp.preprocess(temporal_downsample_factor=1)\n",
    "vp.spatial_filter()\n",
    "vp.motion_correct()\n",
    "vp.run_cnmfe()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = '/mnt/working_storage/spring 2022/4345_project/4345/python_output/4345.pipeline'\n",
    "vp.save(save_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\" not in file_modification lookup, dictionary. Will add the string that was passed.\n",
      "there was a problem running de_interleave.\n",
      "['/mnt/working_storage/spring 2022/4345_project/4345/python_output/2022-02-09-12-49-27_video__efocus_700.isxd', '/mnt/working_storage/spring 2022/4345_project/4345/python_output/2022-02-09-12-49-27_video__efocus_1000.isxd', '/mnt/working_storage/spring 2022/4345_project/4345/python_output/2022-02-09-12-49-27_video__efocus_700.isxd']\n",
      "['700', '1000', 700]\n",
      "ID: 2 efocus: 700 is at step: preprocess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-28-5b5d196335a7>\", line 225, in _de_interleave\n",
      "    isx.de_interleave(obj.previous_step_filepath, fnames_out, planes)\n",
      "  File \"/home/dprotter/Applications/Inscopix Data Processing 1.8.0/Inscopix Data Processing.linux/Contents/API/Python/isx/algo.py\", line 67, in de_interleave\n",
      "    efocus_arr = isx._internal.list_to_ctypes_array(in_efocus_values, ctypes.c_uint16)\n",
      "  File \"/home/dprotter/Applications/Inscopix Data Processing 1.8.0/Inscopix Data Processing.linux/Contents/API/Python/isx/_internal.py\", line 51, in list_to_ctypes_array\n",
      "    array[i] = s\n",
      "TypeError: an integer is required (got type str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some subordinates have failed preprocess:\n",
      "{1: True, 2: False, 3: False, 4: False}\n",
      "ID: 3 efocus: 1000 is at step: preprocess\n",
      "there was a problem running preprocess on SubPipe ID: 3.\n",
      "some subordinates have failed preprocess:\n",
      "{1: True, 2: False, 3: True, 4: False}\n",
      "overwriting previous file at /mnt/working_storage/spring 2022/4345_project/4345/python_output/2022-02-09-12-49-27_video__efocus_700_pp.isxd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-45-d58360a92e3e>\", line 95, in preprocess\n",
      "    overwrite=overwrite)\n",
      "  File \"<ipython-input-28-5b5d196335a7>\", line 56, in _preprocess\n",
      "    trim_early_frames=trim_early_frames)\n",
      "  File \"/home/dprotter/Applications/Inscopix Data Processing 1.8.0/Inscopix Data Processing.linux/Contents/API/Python/isx/algo.py\", line 46, in preprocess\n",
      "    crop_rect[0], crop_rect[1], crop_rect[2], crop_rect[3], fix_defective_pixels, trim_early_frames)\n",
      "  File \"/home/dprotter/Applications/Inscopix Data Processing 1.8.0/Inscopix Data Processing.linux/Contents/API/Python/isx/_internal.py\", line 111, in _standard_errcheck\n",
      "    def _standard_errcheck(return_code, func, args=None):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 4 efocus: 700 is at step: preprocess\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SubPipe' object has no attribute 'get_focal_planes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-490a9c37e4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bottom_subs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_focal_planes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SubPipe' object has no attribute 'get_focal_planes'"
     ]
    }
   ],
   "source": [
    "vp.get_bottom_subs(vp.subordinates[1])[0].get_focal_planes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\" not in file_modification lookup, dictionary. Will add the string that was passed.\n",
      "['/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700.isxd']\n",
      "[300, 500, 700]\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp.isxd\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp.isxd\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp.isxd\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp_sf.isxd\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp_sf.isxd\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp_sf.isxd\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp_sf_mc.isxd\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp_sf_mc.isxd\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp_sf_mc.isxd\n",
      "ID: 2 efocus: 300 is at step: cnmfe\n",
      "skipping processing and utilizing previous file at /mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp_sf_mc_cnmfe.isxd\n",
      "ID: 4 efocus: 700 is at step: cnmfe\n",
      "*****************************\n",
      "SubPipe 2 is at step cnmfe\n",
      "the most recent file is\n",
      "/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp_sf_mc_cnmfe.isxd\n",
      "files to be removed:\n",
      "['/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp_sf.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp_sf.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp_sf.isxd']\n",
      "*****************************\n",
      "\n",
      "*****************************\n",
      "SubPipe 3 is at step cnmfe\n",
      "the most recent file is\n",
      "/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp_sf_mc_cnmfe.isxd\n",
      "files to be removed:\n",
      "['/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp_sf.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp_sf.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp_sf.isxd']\n",
      "*****************************\n",
      "\n",
      "*****************************\n",
      "SubPipe 4 is at step cnmfe\n",
      "the most recent file is\n",
      "/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp_sf_mc_cnmfe.isxd\n",
      "files to be removed:\n",
      "['/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_300_pp_sf.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_500_pp_sf.isxd', '/mnt/working_storage/synch/pipeline_files/2022-04-07-14-29-07_video__efocus_700_pp_sf.isxd']\n",
      "*****************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''file_list = ['/mnt/working_storage/synch/Session-20220405-162135_4664_baseplate/2022-04-05-16-40-58_video.isxd',\n",
    "'/mnt/working_storage/synch/Session-20220405-165748_4665_baseplate/2022-04-05-17-19-14_video.isxd',\n",
    "'/mnt/working_storage/synch/Session-20220407-144223_4659_ig_baseplate/2022-04-07-15-01-04_video.isxd',\n",
    "'/mnt/working_storage/synch/Session-20220407-141746_4660_ig_baseplate/2022-04-07-14-29-07_video.isxd'\n",
    "]\n",
    "\n",
    "session_file_list = ['/mnt/working_storage/synch/Session-20220405-162135_4664_baseplate/session.json',\n",
    "'/mnt/working_storage/synch/Session-20220405-165748_4665_baseplate/session.json',\n",
    "'/mnt/working_storage/synch/Session-20220407-144223_4659_ig_baseplate/session.json',\n",
    "'/mnt/working_storage/synch/Session-20220407-141746_4660_ig_baseplate/session.json'\n",
    "]\n",
    "'''\n",
    "file_list = [\n",
    "'/mnt/working_storage/synch/Session-20220407-141746_4660_ig_baseplate/2022-04-07-14-29-07_video.isxd'\n",
    "]\n",
    "\n",
    "session_file_list = [\n",
    "'/mnt/working_storage/synch/Session-20220407-141746_4660_ig_baseplate/session.json'\n",
    "]\n",
    "\n",
    "\n",
    "output = '/mnt/working_storage/synch/pipeline_files'\n",
    "\n",
    "\n",
    "for file, session_file in zip(file_list, session_file_list):\n",
    "    vp = Video_Pipe(file, session_info_file = session_file, output_dir = output)\n",
    "    if vp.session_info['microscope']['multiplane']['enabled']:\n",
    "        vp.de_interleave(overwrite=False)\n",
    "    vp.preprocess(temporal_downsample_factor=1, overwrite=False)\n",
    "    \n",
    "    vp.spatial_filter(overwrite=False)\n",
    "    \n",
    "    vp.motion_correct(overwrite=False)\n",
    "    \n",
    "    vp.run_cnmfe(overwrite=False)\n",
    "    vp.check_status()\n",
    "    #vp.clean_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "check_failed() missing 1 required positional argument: 'step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-129fbe085a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-821d59a78b5b>\u001b[0m in \u001b[0;36mclean_up\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclean_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_failed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0many_failed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: check_failed() missing 1 required positional argument: 'step'"
     ]
    }
   ],
   "source": [
    "vp.clean_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SubPipe at 0x7f9a813f8630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.subordinates[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0481b4081e895663bd4cba2aedafe56fbc2f9176c8ee358b95e424e83c728ed0"
  },
  "kernelspec": {
   "display_name": "isx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
